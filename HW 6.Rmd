---
title: "Homework 6"
author: "Alyssa Vanderbeek"
date: "27 November 2018"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(modelr)

theme_set(theme_bw())
```

### Problem 1

```{r}
homicide_data = read_csv('./data/problem1/homicide-data.csv') # read in data

homicide_data_tidy = homicide_data %>%
  mutate(city_state = paste(city, toupper(state), sep = ', '), # create city_state variable
         victim_race = fct_relevel(ifelse(victim_race == 'White', 'white', 'non-white'), 'white'), # dichotomize race as factor (white vs. non-white)
         victim_age = ifelse(victim_age == 'Unknown', NA, as.numeric(victim_age)), # make age numeric
         resolved = as.numeric(disposition == "Closed by arrest")) %>% # create binary variable for whether murder is resolved
  filter(!(city_state %in% c('Tulsa, AL', 'Dallas, TX', 'Phoenix, AZ', 'Kansas City, MO'))) # filter cities

str(homicide_data_tidy)

# Logistic regression for all cities
fit_logistic = homicide_data_tidy %>%
  glm(resolved ~ victim_age + victim_race + victim_sex, data = ., family = binomial())

summary(fit_logistic)
  
# Table of estimated OR and 95% CI for race, holding all else constant
fit_logistic %>% 
  broom::tidy() %>% # tidy output
  filter(term == 'victim_racenon-white') %>% # get coefficient for race only
  summarise(OR = exp(estimate),
            '95% CI lower bound' = exp(estimate - qnorm(0.975)*std.error),
            '95% CI upper bound' = exp(estimate + qnorm(0.975)*std.error)) %>% # calculate 95% CI for OR
  knitr::kable(digits = 3)
```

Across all cities in the dataset, the odds of the murder of a non-white person being resolved is 44% less than if the victim were white (all else constant). 

```{r}
# Logistic regression for each city
log_reg_cities = homicide_data_tidy %>%
  select(city_state, resolved, victim_age, victim_race, victim_sex) %>% # select only variables to use in logistic regression
  nest(-city_state) %>% # nest all variables to each city
  mutate(logreg = map(data, ~ broom::tidy(glm(resolved ~ victim_age + victim_race + victim_sex, data = ., family = binomial())))) %>% # map logistic regression with nested data, make output a nested tibble
  select(city_state, logreg) %>% # select only city and model
  unnest %>% 
  filter(term == 'victim_racenon-white') %>% # get coefficients for race only
  rowwise %>%
  summarise(city = city_state,
            OR = exp(estimate),
            ci_lower = exp(estimate - qnorm(0.975)*std.error),
            ci_upper = exp(estimate + qnorm(0.975)*std.error)) # OR and 95% CI for each city

# print table
log_reg_cities %>%
  knitr::kable(digits = 3,
               col.names = c('City', 'OR', '95% CI lower bound', '95% CI upper bound'),
               caption = 'Odds of resolved cases for non-white vs. white victims') # write an actual caption
```


```{r, fig.height=7, fig.width=5}
# plot of OR estimate and CI for each city
log_reg_cities %>%
  mutate(city = fct_reorder(city, OR, desc = T)) %>% # order cities according to OR estimate
  ggplot(aes(x = city, y = OR)) + 
  geom_point() +
  geom_errorbar(aes(x = city, ymin = ci_lower, ymax = ci_upper), width = 0.5) + # error bars for CI bounds
  geom_hline(yintercept = 1, lty = 3) + # dotted line at OR=1 to represent no difference in odds of resolution across races
  labs(y = 'Odds of resolved cases (non-white vs. white)',
       x = 'City') +
  coord_flip()
  
```

The figure above shows the odds ratios for case resolution of white vs. non-white victims (all else constant). All cities on display except for two - Tampa, FL and Birmingham, AL - exhibit a lower odds of resolving murders of non-white victims, compared to white victims. However, estimates of several more cities do not exhibit a statistically significant difference in murder resolution between races (95% CI includes OR of 1); take, for example, Richmond, VA, where the OR is 0.447, but the CI extends from 0.162 to 1.238, suggesting that we cannot exclude the possibility that the true odds of resolution is equal (OR=1). Conversely, the odds of resolution across races is about equal in Durham, NC, but the confidence interval around the estimate is wide. 





### Problem 2

```{r}
birthweight_tidy = read_csv('./data/problem2/birthweight.csv') %>%
  mutate(babysex = fct_recode(as.character(babysex), 'Male' = '1', 'Female' = '2'),
         mrace = fct_recode(as.character(mrace), 'White' = '1', 'Black' = '2', 'Asian' = '3', 'Puerto Rican' = '4'),
         frace = fct_recode(as.character(frace), 'White' = '1', 'Black' = '2', 'Asian' = '3', 'Puerto Rican' = '4', 'Other' = '8'))

str(birthweight_tidy)
```

To construct a regression model, I first included all variables (no interactions) and then removed individually those that were not significant predictors of birthweight.  The full process can be seen in a previous commit. I ended up with the following model. 

```{r}
my_model = lm(bwt ~ babysex + bhead + blength + delwt + mheight + mrace + ppwt + smoken, data = birthweight_tidy) # linear regression model for birthweight
summary(my_model) # summary of my regression model

# Plot of fitted values against residuals
birthweight_tidy %>%
  modelr::add_predictions(my_model) %>% # add predicted birthweight
  modelr::add_residuals(my_model) %>% # residual of observed bwt - predicted bwt
  ggplot(aes(x = pred, y = resid)) + # plot 
  geom_point() + 
  geom_hline(yintercept = 0, col = 'red') + # add line for residual of 0 to better see distribution of residuals
  labs(x = 'Predicted birthweight',
       y = 'Residuals')
```

In examining the relationship between the variables I selected, there is some evidence of nonlinear associations between the baby's size (head circumference and body length) and its weight. However, I decided to omit interaction terms from my model for the sake of simplicity and the scope of this assignment. 

```{r}
birthweight_tidy %>% select(bwt, bhead, blength, delwt, mheight, ppwt, smoken) %>% pairs
```


```{r}
# comparison models
comp_model_1 = lm(bwt ~ blength + gaweeks, data = birthweight_tidy) # comparison model 1
summary(comp_model_1)

comp_model_2 = lm(bwt ~ (bhead + blength + babysex)^3, data = birthweight_tidy) # comparison model 2 with all interaction terms 
summary(comp_model_2)
```

To cross-validate my model and compare it to the other two, I first construct a set of training and testing subset of the original data. I then construct each of the three models based on the training datasets, and use them to predict the outcomes (birthweight) in the testing datasets. How well each model performs is based on the root mean squared error (RMSE) of the predictions.

```{r}
# test/train dataset for cross validation of models
bwt_cv = birthweight_tidy %>%
  crossv_mc(., n = 100) %>% # subset original dataset for cross validation
  mutate(train = map(train, as_tibble), # create train and test subsets
         test = map(test, as_tibble)) %>%
  mutate(my_model = map(train, ~lm(bwt ~ babysex + bhead + blength + delwt + mheight + mrace + ppwt + smoken, data = .x)), # prediction using my model across each training subset
         comp1 = map(train, ~ lm(bwt ~ blength + gaweeks, data = .x)), # prediction with comparison model 1
         comp2 = map(train, ~ lm(bwt ~ (bhead + blength + babysex)^3, data = .x))) %>% # prediction with comparison model 2
  mutate(rmse_my_model    = map2_dbl(my_model, test, ~rmse(model = .x, data = .y)), # RMSE for my model
         rmse_comp1 = map2_dbl(comp1, test, ~rmse(model = .x, data = .y)), # RMSE for comparison model 1
         rmse_comp2 = map2_dbl(comp2, test, ~rmse(model = .x, data = .y))) # RMSE for comparison model 2

# visualizing the distribution of RMSE for each model 
bwt_cv %>% 
  select(starts_with("rmse")) %>% 
  gather(key = model, value = rmse) %>% 
  mutate(model = str_replace(model, "rmse_", ""),
         model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin() + 
  labs(x = 'Model',
       y = 'RMSE',
       title = 'Distribution of RMSE for each regression model')

```

In comparing my model with the two given regressions according to their RMSE, my model appears to be superior, with RMSE values slightly lower than those of the second comparator model. This can be seen in the violin plot above. However, given how close in RMSE the second comparison model is to mine, it may be worth exploring including some of the compariso model's interaction terms in the model I propose. 